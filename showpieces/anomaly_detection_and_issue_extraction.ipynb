{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"../data/calling_relationships_monitoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>Workload</th>\n",
       "      <th>FailCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-23 15:55:00</td>\n",
       "      <td>frontend</td>\n",
       "      <td>adservice</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-23 15:55:00</td>\n",
       "      <td>frontend</td>\n",
       "      <td>checkoutservice</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-23 15:55:00</td>\n",
       "      <td>frontend</td>\n",
       "      <td>shippingservice</td>\n",
       "      <td>250.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-23 15:55:00</td>\n",
       "      <td>frontend</td>\n",
       "      <td>currencyservice</td>\n",
       "      <td>3653.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-23 15:55:00</td>\n",
       "      <td>frontend</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>5172.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281355</th>\n",
       "      <td>2022-04-04 20:59:00</td>\n",
       "      <td>checkoutservice</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281356</th>\n",
       "      <td>2022-04-04 20:59:00</td>\n",
       "      <td>checkoutservice</td>\n",
       "      <td>cartservice</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281357</th>\n",
       "      <td>2022-04-04 20:59:00</td>\n",
       "      <td>recommendationservice</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>1001.333333</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281358</th>\n",
       "      <td>2022-04-04 20:59:00</td>\n",
       "      <td>cartservice</td>\n",
       "      <td>redis-cart</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281359</th>\n",
       "      <td>2022-04-04 20:59:00</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>mysql</td>\n",
       "      <td>3801.333333</td>\n",
       "      <td>14.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281360 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TimeStamp             SourceName        DestinationName  \\\n",
       "0       2022-03-23 15:55:00               frontend              adservice   \n",
       "1       2022-03-23 15:55:00               frontend        checkoutservice   \n",
       "2       2022-03-23 15:55:00               frontend        shippingservice   \n",
       "3       2022-03-23 15:55:00               frontend        currencyservice   \n",
       "4       2022-03-23 15:55:00               frontend  productcatalogservice   \n",
       "...                     ...                    ...                    ...   \n",
       "281355  2022-04-04 20:59:00        checkoutservice  productcatalogservice   \n",
       "281356  2022-04-04 20:59:00        checkoutservice            cartservice   \n",
       "281357  2022-04-04 20:59:00  recommendationservice  productcatalogservice   \n",
       "281358  2022-04-04 20:59:00            cartservice             redis-cart   \n",
       "281359  2022-04-04 20:59:00  productcatalogservice                  mysql   \n",
       "\n",
       "           Workload  FailCount  \n",
       "0        664.000000   0.000000  \n",
       "1         54.666667   0.000000  \n",
       "2        250.666667   0.000000  \n",
       "3       3653.333333   0.000000  \n",
       "4       5172.000000   0.000000  \n",
       "...             ...        ...  \n",
       "281355   104.000000   0.000000  \n",
       "281356    98.666667   0.000000  \n",
       "281357  1001.333333  20.000000  \n",
       "281358   736.000000   0.000000  \n",
       "281359  3801.333333  14.666667  \n",
       "\n",
       "[281360 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ServicePairs = {}\n",
    "for g in all_data.groupby(['SourceName', 'DestinationName']):\n",
    "    ServicePairs[g[0]] = g[1].reset_index(drop=True)\n",
    "    ServicePairs[g[0]]['YesterFailCount'] = ServicePairs[g[0]]['FailCount'].shift(1440).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a simple anomaly detector, only for this simulation dataset as a showpiece. In practice, we can use some more advanced anomaly detectors to achieve a higher anomaly detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ServicePairsAnomalies = {}\n",
    "for pair in ServicePairs:\n",
    "    ServicePairsAnomalies[pair] = ServicePairs[pair]['FailCount']>0\n",
    "    #ServicePairsAnomalies[pair] = pd.Series(np.all([ServicePairsAnomalies[pair],ServicePairsAnomalies[pair].shift(1), ServicePairsAnomalies[pair].shift(2)],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(ServicePairs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = len(ServicePairs[keys[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SystemAnomalies = pd.concat([ServicePairsAnomalies[k] for k in ServicePairsAnomalies], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SystemAnomalies.columns = [k for k in ServicePairsAnomalies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     11592\n",
       "False     5993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SystemAnomalies.any(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SystemAnomalies_any = SystemAnomalies.any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.9\n",
    "min_sample = 1\n",
    "Topologies = []\n",
    "for t in range(9, datalen-1):\n",
    "    if SystemAnomalies_any.loc[t]:\n",
    "        anomalypairs = [k for k in keys if SystemAnomalies.loc[t][k]]\n",
    "        # online boutiques keep 1-edge topologies\n",
    "        if len(anomalypairs) == 1:\n",
    "            topoFea = {}\n",
    "            topoFea['time'] = t\n",
    "            topoFea['edges_info'] = []\n",
    "            edge = anomalypairs[0]\n",
    "            topoedge ={}\n",
    "            topoedge['src'] = edge[0]\n",
    "            topoedge['des'] = edge[1]\n",
    "            topoedge['FailCount'] = ServicePairs[edge].loc[t-9:t]['FailCount'].tolist()\n",
    "            topoedge['Workload'] = ServicePairs[edge].loc[t-9:t]['Workload'].tolist()\n",
    "            topoedge['YesterFailCount'] = ServicePairs[edge].loc[t-9:t]['YesterFailCount'].tolist()\n",
    "                        \n",
    "            topoFea['edges_info'].append(topoedge)\n",
    "            \n",
    "            topoFea['MaxFail'] = topoedge['FailCount'][-1]\n",
    "            topoFea['nodes'] = [edge[0], edge[1]]\n",
    "            topoFea['TimeStamp'] = ServicePairs[edge].loc[t]['TimeStamp']\n",
    "            \n",
    "            Topologies.append(topoFea)\n",
    "        elif len(anomalypairs) > 1:\n",
    "            point_list = [ServicePairs[pair].loc[t-9:t]['FailCount'].tolist() for pair in anomalypairs]\n",
    "\n",
    "            distance_matrix = np.corrcoef(point_list)\n",
    "            distance_matrix[np.isnan(distance_matrix)] = 0\n",
    "            idx = [idx for idx in range(len(distance_matrix))]\n",
    "            distance_matrix[idx, idx] = 1\n",
    "            distance_matrix = np.abs(distance_matrix)\n",
    "            distance_matrix[distance_matrix >= THRESHOLD] = 1\n",
    "            distance_matrix[distance_matrix < THRESHOLD] = 2\n",
    "            y_pred = DBSCAN(eps=1.5, min_samples=min_sample, metric='precomputed').fit_predict(distance_matrix).tolist()\n",
    "\n",
    "            #print(t,y_pred)\n",
    "            \n",
    "            clusters = [[] for i in range(max(y_pred)+1)]\n",
    "            for i, ano_pair in enumerate(anomalypairs):\n",
    "                clusters[y_pred[i]].append(ano_pair)\n",
    "            \n",
    "            for cluster in clusters:\n",
    "                g = nx.Graph()\n",
    "                di_g = nx.DiGraph()\n",
    "                \n",
    "                g.add_edges_from(cluster)\n",
    "                di_g.add_edges_from(cluster)\n",
    "                \n",
    "                for sub_g in nx.connected_components(g):\n",
    "                    topoFea = {}\n",
    "                    topoFea['time'] = t\n",
    "                    topoFea['edges_info'] = []\n",
    "                    MaxFail = 0\n",
    "                    for edge in list(di_g.subgraph(sub_g).edges):\n",
    "                        topoedge ={}\n",
    "                        topoedge['src'] = edge[0]\n",
    "                        topoedge['des'] = edge[1]\n",
    "                        topoedge['FailCount'] = ServicePairs[edge].loc[t-9:t]['FailCount'].tolist()\n",
    "                        topoedge['Workload'] = ServicePairs[edge].loc[t-9:t]['Workload'].tolist()\n",
    "                        topoedge['YesterFailCount'] = ServicePairs[edge].loc[t-9:t]['YesterFailCount'].tolist()\n",
    "                        \n",
    "                        topoFea['edges_info'].append(topoedge)\n",
    "                        MaxFail = max(MaxFail, topoedge['FailCount'][-1])\n",
    "                    \n",
    "                    topoFea['MaxFail'] = MaxFail\n",
    "                    topoFea['nodes'] = list(sub_g)\n",
    "                    topoFea['TimeStamp'] = ServicePairs[edge].loc[t]['TimeStamp']\n",
    "                    Topologies.append(topoFea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26132"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Topologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw_topoloies.pkl', 'wb') as f:\n",
    "    pickle.dump(Topologies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
